{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"「hw12_reinforcement_learning_chinese_version.ipynb」的副本","provenance":[{"file_id":"https://github.com/ga642381/ML2021-Spring/blob/main/HW12/HW12_ZH.ipynb","timestamp":1624002552270}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"47b44b3e42b94cf0b0f1ffdc38c676cd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d19a9f91be0b43f8ad9ac4935323ff7a","IPY_MODEL_116f38806106401bba1919b1640a6854"],"layout":"IPY_MODEL_baa28ec319f84251bf98eb5db34df9af"}},"d19a9f91be0b43f8ad9ac4935323ff7a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"Total:  300.5, Final:  100.0: 100%","description_tooltip":null,"layout":"IPY_MODEL_f9c3b71c07644f93aad5a8e5e41fb910","max":5000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e280bb585a3f4bb4b7e761844c897c9b","value":5000}},"116f38806106401bba1919b1640a6854":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4517cb42b6c841a6a72360f205eddc04","placeholder":"​","style":"IPY_MODEL_695a70b1f75e4b4f888589947158e199","value":" 5000/5000 [32:09&lt;00:00,  2.59it/s]"}},"baa28ec319f84251bf98eb5db34df9af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9c3b71c07644f93aad5a8e5e41fb910":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e280bb585a3f4bb4b7e761844c897c9b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"4517cb42b6c841a6a72360f205eddc04":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"695a70b1f75e4b4f888589947158e199":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"Fp30SB4bxeQb"},"source":["# **Homework 12 - Reinforcement Learning**\n","\n","若有任何問題，歡迎來信至助教信箱 ntu-ml-2021spring-ta@googlegroups.com\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UpC0w2Q5IN6y","executionInfo":{"elapsed":279,"status":"ok","timestamp":1624121472446,"user":{"displayName":"張君豪","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giewpu4H1RC4LywWkj1iyfrLc5i6hgwttwazWU6EQ=s64","userId":"03999016312843703738"},"user_tz":-480},"outputId":"79f33784-8d8b-417d-e5b2-c26479682620"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Sat Jun 19 16:51:12 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   42C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B31tyauy6fUn","executionInfo":{"elapsed":308,"status":"ok","timestamp":1624121474600,"user":{"displayName":"張君豪","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giewpu4H1RC4LywWkj1iyfrLc5i6hgwttwazWU6EQ=s64","userId":"03999016312843703738"},"user_tz":-480},"outputId":"4a1632b5-2d20-4627-f6cb-58bc2871ad00"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yXsnCWPtWSNk"},"source":["## 前置作業\n","\n","首先我們需要安裝必要的系統套件及 PyPi 套件。\n","gym 這個套件由 OpenAI 所提供，是一套用來開發與比較 Reinforcement Learning 演算法的工具包（toolkit）。\n","而其餘套件則是為了在 Notebook 中繪圖所需要的套件。"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5e2bScpnkVbv","executionInfo":{"elapsed":7500,"status":"ok","timestamp":1624121484619,"user":{"displayName":"張君豪","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giewpu4H1RC4LywWkj1iyfrLc5i6hgwttwazWU6EQ=s64","userId":"03999016312843703738"},"user_tz":-480},"outputId":"491255d4-bd83-4cc6-bf54-a86818094c8c"},"source":["save_path = './drive/MyDrive/ML大金/HW12/'\n","!apt update\n","!apt install python-opengl xvfb -y\n","!pip install gym[box2d]==0.18.3 pyvirtualdisplay tqdm numpy==1.19.5 torch==1.8.1"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","\u001b[33m\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [1 InRelease 14.2 kB/88.7\u001b[0m\r                                                                               \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n","\u001b[33m\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [1 InRelease 43.1 kB/88.7\u001b[0m\u001b[33m\r0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.152)\u001b[0m\u001b[33m\r0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.152)\u001b[0m\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","\u001b[33m\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Wait\u001b[0m\r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu bionic InRelease\n","\u001b[33m\r                                                                               \r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers]\u001b[0m\r                                                                         \rHit:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n","\u001b[33m\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers]\u001b[0m\r                                                                         \rIgn:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n","Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n","Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Fetched 252 kB in 2s (144 kB/s)\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","47 packages can be upgraded. Run 'apt list --upgradable' to see them.\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","python-opengl is already the newest version (3.1.0+dfsg-1).\n","xvfb is already the newest version (2:1.19.6-1ubuntu4.9).\n","0 upgraded, 0 newly installed, 0 to remove and 47 not upgraded.\n","Requirement already satisfied: gym[box2d]==0.18.3 in /usr/local/lib/python3.7/dist-packages (0.18.3)\n","Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.7/dist-packages (2.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n","Requirement already satisfied: numpy==1.19.5 in /usr/local/lib/python3.7/dist-packages (1.19.5)\n","Requirement already satisfied: torch==1.8.1 in /usr/local/lib/python3.7/dist-packages (1.8.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.18.3) (1.4.1)\n","Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.18.3) (1.3.0)\n","Requirement already satisfied: Pillow<=8.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.18.3) (7.1.2)\n","Requirement already satisfied: pyglet<=1.5.15,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.18.3) (1.5.0)\n","Requirement already satisfied: box2d-py~=2.3.5; extra == \"box2d\" in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.18.3) (2.3.8)\n","Requirement already satisfied: EasyProcess in /usr/local/lib/python3.7/dist-packages (from pyvirtualdisplay) (0.3)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1) (3.7.4.3)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.15,>=1.4.0->gym[box2d]==0.18.3) (0.16.0)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"M_-i3cdoYsks"},"source":["接下來，設置好 virtual display，並引入所有必要的套件。"]},{"cell_type":"code","metadata":{"id":"nl2nREINDLiw"},"source":["%%capture\n","from pyvirtualdisplay import Display\n","virtual_display = Display(visible=0, size=(1400, 900))\n","virtual_display.start()\n","\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","from IPython import display\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.distributions import Categorical\n","from tqdm.notebook import tqdm"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HVu9-Vdrl4E3"},"source":["# 請不要更改 random seed !!!!\n","# 不然在judgeboi上 你的成績不會被reproduce !!!!"]},{"cell_type":"code","metadata":{"id":"fV9i8i2YkRbO"},"source":["seed = 543 # Do not change this\n","def fix(env, seed):\n","  env.seed(seed)\n","  env.action_space.seed(seed)\n","  torch.manual_seed(seed)\n","  torch.cuda.manual_seed(seed)\n","  torch.cuda.manual_seed_all(seed)\n","  np.random.seed(seed)\n","  random.seed(seed)\n","  torch.set_deterministic(True)\n","  torch.backends.cudnn.benchmark = False\n","  torch.backends.cudnn.deterministic = True"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"He0XDx6bzjgC"},"source":["最後，引入 OpenAI 的 gym，並建立一個 [Lunar Lander](https://gym.openai.com/envs/LunarLander-v2/) 環境。"]},{"cell_type":"code","metadata":{"id":"N_4-xJcbBt09"},"source":["%%capture\n","import gym\n","import random\n","import numpy as np\n","\n","env = gym.make('LunarLander-v2')\n","\n","fix(env, seed)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NmiAOfqRwRX5"},"source":["import time\n","start = time.time()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NrkVvTrvWZ5H"},"source":["## 什麼是 Lunar Lander？\n","\n","“LunarLander-v2” 這個環境是在模擬登月小艇降落在月球表面時的情形。\n","這個任務的目標是讓登月小艇「安全地」降落在兩個黃色旗幟間的平地上。\n","> Landing pad is always at coordinates (0,0).\n","> Coordinates are the first two numbers in state vector.\n","\n","![](https://gym.openai.com/assets/docs/aeloop-138c89d44114492fd02822303e6b4b07213010bb14ca5856d2d49d6b62d88e53.svg)\n","\n","所謂的「環境」其實同時包括了 agent 和 environment。\n","我們利用 `step()` 這個函式讓 agent 行動，而後函式便會回傳 environment 給予的 observation/state（以下這兩個名詞代表同樣的意思）和 reward。"]},{"cell_type":"markdown","metadata":{"id":"bIbp82sljvAt"},"source":["### Observation / State\n","\n","首先，我們可以看看 environment 回傳給 agent 的 observation 究竟是長什麼樣子的資料："]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rsXZra3N9R5T","executionInfo":{"elapsed":269,"status":"ok","timestamp":1624086567293,"user":{"displayName":"張君豪","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giewpu4H1RC4LywWkj1iyfrLc5i6hgwttwazWU6EQ=s64","userId":"03999016312843703738"},"user_tz":-480},"outputId":"c7707a10-a59a-45c0-cec1-689e4f743fb4"},"source":["print(env.observation_space)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Box(-inf, inf, (8,), float32)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ezdfoThbAQ49"},"source":["`Box(8,)` 說明我們會拿到 8 維的向量作為 observation，其中包含：垂直及水平座標、速度、角度、加速度等等，這部分我們就不細說。\n","\n","### Action\n","\n","而在 agent 得到 observation 和 reward 以後，能夠採取的動作有："]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p1k4dIrBAaKi","executionInfo":{"elapsed":5,"status":"ok","timestamp":1624086569184,"user":{"displayName":"張君豪","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giewpu4H1RC4LywWkj1iyfrLc5i6hgwttwazWU6EQ=s64","userId":"03999016312843703738"},"user_tz":-480},"outputId":"382bbd68-e5bd-4022-c426-9df3b8cfa92f"},"source":["print(env.action_space)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Discrete(4)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dejXT6PHBrPn"},"source":["`Discrete(4)` 說明 agent 可以採取四種離散的行動：\n","- 0 代表不採取任何行動\n","- 2 代表主引擎向下噴射\n","- 1, 3 則是向左右噴射\n","\n","接下來，我們嘗試讓 agent 與 environment 互動。\n","在進行任何操作前，建議先呼叫 `reset()` 函式讓整個「環境」重置。\n","而這個函式同時會回傳「環境」最初始的狀態。"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pi4OmrmZgnWA","executionInfo":{"elapsed":418,"status":"ok","timestamp":1624086570818,"user":{"displayName":"張君豪","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giewpu4H1RC4LywWkj1iyfrLc5i6hgwttwazWU6EQ=s64","userId":"03999016312843703738"},"user_tz":-480},"outputId":"17402346-39fc-47ea-a52c-20a26c0550e5"},"source":["initial_state = env.reset()\n","print(initial_state)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[ 0.00396109  1.4083536   0.40119505 -0.11407257 -0.00458307 -0.09087662\n","  0.          0.        ]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uBx0mEqqgxJ9"},"source":["接著，我們試著從 agent 的四種行動空間中，隨機採取一個行動"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vxkOEXRKgizt","executionInfo":{"elapsed":258,"status":"ok","timestamp":1624086572769,"user":{"displayName":"張君豪","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giewpu4H1RC4LywWkj1iyfrLc5i6hgwttwazWU6EQ=s64","userId":"03999016312843703738"},"user_tz":-480},"outputId":"1206f822-6af0-4e4c-ee86-91a23511e170"},"source":["random_action = env.action_space.sample()\n","print(random_action)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mns-bO01g0-J"},"source":["再利用 `step()` 函式讓 agent 根據我們隨機抽樣出來的 `random_action` 動作。\n","而這個函式會回傳四項資訊：\n","- observation / state\n","- reward\n","- 完成與否\n","- 其餘資訊"]},{"cell_type":"code","metadata":{"id":"E_WViSxGgIk9"},"source":["observation, reward, done, info = env.step(random_action)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FdieGq7NuBIm"},"source":["第一項資訊 `observation` 即為 agent 採取行動之後，agent 對於環境的 observation 或者說環境的 state 為何。\n","而第三項資訊 `done` 則是 `True` 或 `False` 的布林值，當登月小艇成功著陸或是不幸墜毀時，代表這個回合（episode）也就跟著結束了，此時 `step()` 函式便會回傳 `done = True`，而在那之前，`done` 則保持 `False`。"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yK7r126kuCNp","executionInfo":{"elapsed":5,"status":"ok","timestamp":1624086576867,"user":{"displayName":"張君豪","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giewpu4H1RC4LywWkj1iyfrLc5i6hgwttwazWU6EQ=s64","userId":"03999016312843703738"},"user_tz":-480},"outputId":"af6f78d5-9a2d-4493-d3b2-f0592137f748"},"source":["print(done)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["False\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GKdS8vOihxhc"},"source":["### Reward\n","\n","而「環境」給予的 reward 大致是這樣計算：\n","- 小艇墜毀得到 -100 分\n","- 小艇在黃旗幟之間成功著地則得 100~140 分\n","- 噴射主引擎（向下噴火）每次 -0.3 分\n","- 小艇最終完全靜止則再得 100 分\n","- 小艇每隻腳碰觸地面 +10 分\n","\n","> Reward for moving from the top of the screen to landing pad and zero speed is about 100..140 points.\n","> If lander moves away from landing pad it loses reward back.\n","> Episode finishes if the lander crashes or comes to rest, receiving additional -100 or +100 points.\n","> Each leg ground contact is +10.\n","> Firing main engine is -0.3 points each frame.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vxQNs77hi0_7","executionInfo":{"elapsed":291,"status":"ok","timestamp":1624086580300,"user":{"displayName":"張君豪","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giewpu4H1RC4LywWkj1iyfrLc5i6hgwttwazWU6EQ=s64","userId":"03999016312843703738"},"user_tz":-480},"outputId":"87ff7d5b-b3c4-4b2a-e16c-0edd4046d3af"},"source":["print(reward) # after doing a random action (0), the immediate reward is stored in this "],"execution_count":null,"outputs":[{"output_type":"stream","text":["-0.8588900517154912\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Mhqp6D-XgHpe"},"source":["### Random Agent\n","\n","最後，在進入實做之前，我們就來看看這樣一個 random agent 能否成功登陸月球："]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":395},"id":"Y3G0bxoccelv","executionInfo":{"elapsed":381,"status":"error","timestamp":1624086582858,"user":{"displayName":"張君豪","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giewpu4H1RC4LywWkj1iyfrLc5i6hgwttwazWU6EQ=s64","userId":"03999016312843703738"},"user_tz":-480},"outputId":"fc0a7d56-76d0-443c-eaa2-f7aa325e47ad"},"source":["env.reset()\n","\n","img = plt.imshow(env.render(mode='rgb_array'))\n","\n","done = False\n","while not done:\n","    action = env.action_space.sample()\n","    observation, reward, done, _ = env.step(action)\n","\n","    img.set_data(env.render(mode='rgb_array'))\n","    display.display(plt.gcf())\n","    display.clear_output(wait=True)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-38-8d8eb33f4d26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/envs/box2d/lunar_lander.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassic_control\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mViewer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVIEWPORT_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVIEWPORT_H\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/envs/classic_control/rendering.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     raise ImportError('''\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyglet/gl/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0mcompat_platform\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'darwin'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcocoa\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCocoaConfig\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mbase\u001b[0m  \u001b[0;31m# noqa: F821\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'base' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"F5paWqo7tWL2"},"source":["## Policy Gradient\n","\n","現在來搭建一個簡單的 policy network。\n","我們預設模型的輸入是 8-dim 的 observation，輸出則是離散的四個動作之一："]},{"cell_type":"code","metadata":{"id":"J8tdmeD-tZew"},"source":["class PolicyGradientNetwork(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.Dense = nn.Sequential(\n","            nn.Linear(8, 16),\n","            nn.ReLU(),\n","            nn.Linear(16, 16),\n","            nn.ReLU(),\n","            nn.Linear(16, 4),\n","            nn.Softmax()\n","        )\n","\n","    def forward(self, state):\n","        return self.Dense(state)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ynbqJrhIFTC3"},"source":["再來，搭建一個簡單的 agent，並搭配上方的 policy network 來採取行動。\n","這個 agent 能做到以下幾件事：\n","- `learn()`：從記下來的 log probabilities 及 rewards 來更新 policy network。\n","- `sample()`：從 environment 得到 observation 之後，利用 policy network 得出應該採取的行動。\n","而此函式除了回傳抽樣出來的 action，也會回傳此次抽樣的 log probabilities。"]},{"cell_type":"code","metadata":{"id":"zZo-IxJx286z"},"source":["class PolicyGradientAgent():\n","    def __init__(self, network):\n","        self.network = network\n","        self.optimizer = optim.Adam(self.network.parameters(), lr=0.001)\n","         \n","    def forward(self, state):\n","        return self.network(state)\n","\n","    def learn(self, log_probs, rewards):\n","        loss = (-log_probs * rewards).sum() # You don't need to revise this to pass simple baseline (but you can)\n","\n","        self.optimizer.zero_grad()\n","        loss.backward(retain_graph=True)\n","        self.optimizer.step()\n","        \n","    def sample(self, state):\n","        action_prob = self.network(torch.FloatTensor(state))\n","        action_dist = Categorical(action_prob)\n","        action = action_dist.sample()\n","        log_prob = action_dist.log_prob(action)\n","        \n","        return action.item(), log_prob\n","\n","    def save(self, PATH): # You should not revise this\n","        Agent_Dict = {\n","            \"network\" : self.network.state_dict(),\n","            \"optimizer\" : self.optimizer.state_dict()\n","        }\n","        torch.save(Agent_Dict, PATH)\n","\n","    def load(self, PATH): # You should not revise this\n","        checkpoint = torch.load(PATH)\n","        self.network.load_state_dict(checkpoint[\"network\"])\n","        #如果要儲存過程或是中斷訓練後想繼續可以用喔 ^_^\n","        self.optimizer.load_state_dict(checkpoint[\"optimizer\"])\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vCMYHWkDhhxm"},"source":["## Actor critic\n","\n","輸入state，預測本回合會得到幾分，並把超過這個分數的discounted reward視為好(正)，反之視為不好(負)"]},{"cell_type":"code","metadata":{"id":"x5bf8xA-hmts"},"source":["class ActorCriticNetwork(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.Dense = nn.Sequential(\n","            nn.Linear(8, 16),\n","            nn.ReLU(),\n","            nn.Linear(16, 32),\n","            nn.ReLU(),\n","            nn.Linear(32, 16),\n","            nn.ReLU(),\n","            nn.Linear(16, 1),\n","        )\n","\n","    def forward(self, state):\n","        return self.Dense(state)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TN4SjG7_mhmB"},"source":["class ActorCriticAgent():\n","    def __init__(self, network):\n","        self.network = network\n","        self.optimizer = optim.Adam(self.network.parameters(), lr=0.001)\n","         \n","    def forward(self, state):\n","        return self.network(torch.FloatTensor(state))\n","\n","    def learn(self, baselines, rewards):\n","        criterion = nn.MSELoss()\n","        loss = criterion(baselines, rewards)\n","\n","        self.optimizer.zero_grad()\n","        loss.backward()\n","        self.optimizer.step()\n","\n","    def save(self, PATH): # You should not revise this\n","        Agent_Dict = {\n","            \"network\" : self.network.state_dict(),\n","            \"optimizer\" : self.optimizer.state_dict()\n","        }\n","        torch.save(Agent_Dict, PATH)\n","\n","    def load(self, PATH): # You should not revise this\n","        checkpoint = torch.load(PATH)\n","        self.network.load_state_dict(checkpoint[\"network\"])\n","        #如果要儲存過程或是中斷訓練後想繼續可以用喔 ^_^\n","        self.optimizer.load_state_dict(checkpoint[\"optimizer\"])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ehPlnTKyRZf9"},"source":["最後，建立一個 network 和 agent，就可以開始進行訓練了。"]},{"cell_type":"code","metadata":{"id":"GfJIvML-RYjL"},"source":["PG_network = PolicyGradientNetwork()\n","agent = PolicyGradientAgent(PG_network)\n","AC_network = ActorCriticNetwork()\n","baseAgent = ActorCriticAgent(AC_network)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ouv23glgf5Qt"},"source":["## 訓練 Agent\n","\n","現在我們開始訓練 agent。\n","透過讓 agent 和 environment 互動，我們記住每一組對應的 log probabilities 及 reward，並在成功登陸或者不幸墜毀後，回放這些「記憶」來訓練 policy network。"]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":124,"referenced_widgets":["47b44b3e42b94cf0b0f1ffdc38c676cd","d19a9f91be0b43f8ad9ac4935323ff7a","116f38806106401bba1919b1640a6854","baa28ec319f84251bf98eb5db34df9af","f9c3b71c07644f93aad5a8e5e41fb910","e280bb585a3f4bb4b7e761844c897c9b","4517cb42b6c841a6a72360f205eddc04","695a70b1f75e4b4f888589947158e199"]},"id":"vg5rxBBaf38_","outputId":"b917c196-7805-49e8-d1e5-e08f41dce318"},"source":["load = True\n","if load:\n","    agent.load(save_path + 'PG.pt')\n","    baseAgent.load(save_path + 'AC.pt')\n","    print('Network loaded!')\n","\n","agent.network.train()  # 訓練前，先確保 network 處在 training 模式\n","baseAgent.network.train()\n","EPISODE_PER_BATCH = 1  # 每蒐集 5 個 episodes 更新一次 agent\n","NUM_BATCH = 5000        # 總共更新 400 次\n","gama = 0.99\n","\n","avg_total_rewards, avg_final_rewards = [], []\n","\n","prg_bar = tqdm(range(NUM_BATCH))\n","for batch in prg_bar:\n","\n","    log_probs, rewards, baselines = [], [], []\n","    total_rewards, final_rewards = [], []\n","\n","    # 蒐集訓練資料\n","    for episode in range(EPISODE_PER_BATCH):\n","        \n","        state = env.reset()\n","        total_reward, total_step = 0, 0\n","        seq_rewards = []\n","        while True:\n","\n","            action, log_prob = agent.sample(state) # at, log(at|st)\n","            next_state, reward, done, _ = env.step(action)\n","\n","            log_probs.append(log_prob) # [log(a1|s1), log(a2|s2), ...., log(at|st)]\n","            # seq_rewards.append(reward)\n","            for idx in range(len(rewards)):\n","                rewards[idx] += reward * gama**(total_step - idx)\n","            rewards.append(reward) #改這裡\n","\n","            baseline = baseAgent.forward(state) # DQN\n","            baselines.append(baseline)\n","            # ! 重要 ！\n","            # 現在的reward 的implementation 為每個時刻的瞬時reward, 給定action_list : a1, a2, a3 ......\n","            #                                                       reward :     r1, r2 ,r3 ......\n","            # medium：將reward調整成accumulative decaying reward, 給定action_list : a1,                         a2,                           a3 ......\n","            #                                                       reward :     r1+0.99*r2+0.99^2*r3+......, r2+0.99*r3+0.99^2*r4+...... ,r3+0.99*r4+0.99^2*r5+ ......\n","            # boss : implement DQN\n","\n","            state = next_state\n","            total_reward += reward\n","            total_step += 1\n","\n","            if done:\n","                final_rewards.append(reward)\n","                total_rewards.append(total_reward)\n","                break\n","\n","    # print(f\"rewards looks like \", np.shape(rewards))  \n","    # print(f\"log_probs looks like \", np.shape(log_probs))  \n","    # print(f\"baselines looks like \", np.shape(baselines))    \n","    # 紀錄訓練過程\n","    avg_total_reward = sum(total_rewards) / len(total_rewards)\n","    avg_final_reward = sum(final_rewards) / len(final_rewards)\n","    avg_total_rewards.append(avg_total_reward)\n","    avg_final_rewards.append(avg_final_reward)\n","    prg_bar.set_description(f\"Total: {avg_total_reward: 4.1f}, Final: {avg_final_reward: 4.1f}\")\n","\n","    # 更新網路\n","    # rewards = np.concatenate(rewards, axis=0)\n","    # rewards = torch.from_numpy((rewards - np.mean(rewards)) / (np.std(rewards) + 1e-9))  # 將 reward 正規標準化\n","    baselines = torch.stack(baselines).squeeze()\n","    log_probs = torch.stack(log_probs)\n","    rewards = torch.FloatTensor(rewards) - baselines\n","\n","    agent.learn(log_probs, rewards)\n","    baseAgent.learn(baselines, rewards)\n","    # print(\"logs prob looks like \", log_probs.size())\n","    # print(\"torch.from_numpy(rewards) looks like \", rewards.size())\n","    # print(\"torch.from_numpy(baselines) looks like \", baselines.size())\n","\n","    agent.save(save_path + 'PG.pt')\n","    baseAgent.save(save_path + 'AC.pt')\n","\n","print('Done!')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Network loaded!\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"47b44b3e42b94cf0b0f1ffdc38c676cd","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=5000.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:119: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  input = module(input)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"vNb_tuFYhKVK"},"source":["### 訓練結果\n","\n","訓練過程中，我們持續記下了 `avg_total_reward`，這個數值代表的是：每次更新 policy network 前，我們讓 agent 玩數個回合（episodes），而這些回合的平均 total rewards 為何。\n","理論上，若是 agent 一直在進步，則所得到的 `avg_total_reward` 也會持續上升，直至 250 上下。\n","若將其畫出來則結果如下："]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":226},"id":"wZYOI8H10SHN","executionInfo":{"status":"error","timestamp":1624123605723,"user_tz":-480,"elapsed":282,"user":{"displayName":"張君豪","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giewpu4H1RC4LywWkj1iyfrLc5i6hgwttwazWU6EQ=s64","userId":"03999016312843703738"}},"outputId":"bc5c2797-bb72-4fb9-df01-7f6705065b40"},"source":["end = time.time()\n","plt.plot(avg_total_rewards)\n","plt.title(\"Total Rewards\")\n","plt.show()"],"execution_count":21,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-a6fd66707434>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_total_rewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total Rewards\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"mV5jj4dThz0Y"},"source":["另外，`avg_final_reward` 代表的是多個回合的平均 final rewards，而 final reward 即是 agent 在單一回合中拿到的最後一個 reward。\n","如果同學們還記得環境給予登月小艇 reward 的方式，便會知道，不論**回合的最後**小艇是不幸墜毀、飛出畫面、或是靜止在地面上，都會受到額外地獎勵或處罰。\n","也因此，final reward 可被用來觀察 agent 的「著地」是否順利等資訊。"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":281},"id":"txDZ5vlGWz5w","executionInfo":{"elapsed":323,"status":"ok","timestamp":1624121440764,"user":{"displayName":"張君豪","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giewpu4H1RC4LywWkj1iyfrLc5i6hgwttwazWU6EQ=s64","userId":"03999016312843703738"},"user_tz":-480},"outputId":"db4f30e9-eda5-4fde-fa2c-ba22fb2c89e2"},"source":["plt.plot(avg_final_rewards)\n","plt.title(\"Final Rewards\")\n","plt.show()\n"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"gyT7tNwkVdS-"},"source":["訓練時間\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_t-JsKxUViFy","executionInfo":{"elapsed":261,"status":"ok","timestamp":1624121443929,"user":{"displayName":"張君豪","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giewpu4H1RC4LywWkj1iyfrLc5i6hgwttwazWU6EQ=s64","userId":"03999016312843703738"},"user_tz":-480},"outputId":"7cefc4ca-3404-4436-f9d2-7a558e42b990"},"source":["print(f\"total time is {end-start} sec\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["total time is 3179.340103626251 sec\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"u2HaGRVEYGQS"},"source":["## 測試"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":544},"id":"5yFuUKKRYH73","executionInfo":{"status":"ok","timestamp":1624123612099,"user_tz":-480,"elapsed":1609,"user":{"displayName":"張君豪","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giewpu4H1RC4LywWkj1iyfrLc5i6hgwttwazWU6EQ=s64","userId":"03999016312843703738"}},"outputId":"eadd5033-4839-469e-ba00-cc05d51343ac"},"source":["fix(env, seed)\n","agent.load(save_path + 'PG.pt')\n","# baseAgent.load(save_path + 'AC.pt')\n","agent.network.eval()  # 測試前先將 network 切換為 evaluation 模式\n","# baseAgent.network.eval()\n","NUM_OF_TEST = 5 # Do not revise it !!!!!\n","test_total_reward = []\n","action_list = []\n","for i in range(NUM_OF_TEST):\n","  actions = []\n","  state = env.reset()\n","\n","  img = plt.imshow(env.render(mode='rgb_array'))\n","\n","  total_reward = 0\n","\n","  done = False\n","  while not done:\n","      action, _ = agent.sample(state)\n","      actions.append(action)\n","      state, reward, done, _ = env.step(action)\n","\n","      total_reward += reward\n","\n","      # img.set_data(env.render(mode='rgb_array'))\n","      # display.display(plt.gcf())\n","      # display.clear_output(wait=True)\n","  print(total_reward)\n","  test_total_reward.append(total_reward)\n","\n","  action_list.append(actions) #儲存你測試的結果\n","  print(\"length of actions is \", len(actions))"],"execution_count":22,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/__init__.py:422: UserWarning: torch.set_deterministic is deprecated and will be removed in a future release. Please use torch.use_deterministic_algorithms instead\n","  \"torch.set_deterministic is deprecated and will be removed in a future \"\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:119: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  input = module(input)\n"],"name":"stderr"},{"output_type":"stream","text":["256.5412392820635\n","length of actions is  296\n","272.12515120181126\n","length of actions is  261\n","281.85853912541745\n","length of actions is  334\n","236.97831866015747\n","length of actions is  257\n","280.67343262076724\n","length of actions is  242\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Aex7mcKr0J01","executionInfo":{"status":"ok","timestamp":1624123615368,"user_tz":-480,"elapsed":262,"user":{"displayName":"張君豪","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giewpu4H1RC4LywWkj1iyfrLc5i6hgwttwazWU6EQ=s64","userId":"03999016312843703738"}},"outputId":"0b3e82fa-a666-406c-9432-5ea24f6d10ba"},"source":["print(f\"Your final reward is : %.2f\"%np.mean(test_total_reward))"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Your final reward is : 265.64\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"leyebGYRpqsF"},"source":["Action list 的長相"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hGAH4YWDpp4u","executionInfo":{"elapsed":261,"status":"ok","timestamp":1624121502487,"user":{"displayName":"張君豪","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giewpu4H1RC4LywWkj1iyfrLc5i6hgwttwazWU6EQ=s64","userId":"03999016312843703738"},"user_tz":-480},"outputId":"60895fb4-64a3-4714-a1aa-942b07836ee6"},"source":["print(\"Action list looks like \", action_list)\n","print(\"Action list's shape looks like \", np.shape(action_list))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Action list looks like  [[0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 3, 0, 0, 0, 1, 3, 2, 2, 0, 2, 1, 0, 3, 2, 2, 2, 3, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 3, 2, 2, 3, 2, 2, 2, 2, 2, 2, 3, 2, 3, 2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 3, 2, 1, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 1, 2, 2, 2, 2, 2, 3, 1, 3, 1, 1, 2, 2, 2, 1, 3, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 1, 3, 2, 2, 2, 2, 2, 2, 1, 1, 2, 3, 2, 1, 2, 2, 3, 2, 0, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 2, 1, 2, 3, 2, 0, 0, 2, 3, 0, 0, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 3, 2, 2, 2, 2, 2, 3, 2, 2, 3, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 3, 2, 2, 3, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 1, 3, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 0, 2, 2, 2, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 2, 0, 0, 0, 3, 2, 2, 0, 0, 2, 0, 2, 2, 2, 0, 1, 3, 2, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 3, 3, 0, 0, 0, 1, 2, 1, 2, 3, 2, 2, 2, 2, 3, 2, 2, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 3, 2, 2, 0, 2, 2, 3, 3, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 0, 2, 2, 2, 3, 2, 2, 2, 2, 1, 3, 1, 2, 2, 2, 3, 2, 2, 1, 1, 2, 2, 2, 2, 2, 0, 1, 0, 3, 2, 2, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 1, 3, 0, 3, 3, 2, 0, 1, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 3, 3, 3, 3, 3, 3, 0, 3, 0, 2, 3, 2, 2, 3, 2, 2, 2, 0, 1, 0, 1, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 3, 3, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 0, 2, 1, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 1, 2, 0, 2, 1, 2, 2, 1, 2, 2, 1, 0, 2, 2, 1, 2, 2, 3, 3, 0, 1, 2, 0, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 1, 1, 2, 2, 2, 1, 1, 2, 2, 1, 1, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 3, 3, 0, 1, 0, 3, 0, 0, 0, 1, 2, 3, 1, 1, 3, 0, 1, 2, 2, 2, 2, 3, 2, 1, 2, 2, 3, 2, 1, 1, 3, 2, 2, 2, 2, 3, 2, 2, 2, 2, 1, 1, 2, 1, 2, 2, 2, 2, 3, 3, 1, 2, 1, 2, 2, 2, 0, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 3, 2, 2, 3, 2, 2, 2, 1, 2, 3, 2, 3, 2, 3, 2, 2, 2, 3, 2, 2, 2, 1, 2, 2, 2, 0, 2, 2, 3, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 0, 2, 2, 0, 2, 2, 3, 2, 2, 0, 2, 2, 2, 0, 1, 2, 2, 0, 2, 1, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n","Action list's shape looks like  (5,)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  return array(a, dtype, copy=False, order=order)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"l7sokqEUtrFY"},"source":["Action 的分布\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WHdAItjj1nxw","executionInfo":{"elapsed":258,"status":"ok","timestamp":1624121505611,"user":{"displayName":"張君豪","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giewpu4H1RC4LywWkj1iyfrLc5i6hgwttwazWU6EQ=s64","userId":"03999016312843703738"},"user_tz":-480},"outputId":"f0d52a47-06d4-43b5-fb2f-b0021ec5d013"},"source":["distribution = {}\n","for actions in action_list:\n","  for action in actions:\n","    if action not in distribution.keys():\n","      distribution[action] = 1\n","    else:\n","      distribution[action] += 1\n","print(distribution)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{0: 556, 1: 113, 3: 101, 2: 417}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ricE0schY75M"},"source":["儲存 Model Testing的結果\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GZsMkGmIY42b","executionInfo":{"elapsed":266,"status":"ok","timestamp":1624121507847,"user":{"displayName":"張君豪","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giewpu4H1RC4LywWkj1iyfrLc5i6hgwttwazWU6EQ=s64","userId":"03999016312843703738"},"user_tz":-480},"outputId":"b38d9b98-7e94-4e9a-8354-adb335bf90f2"},"source":["PATH = \"Action_List_test.npy\" # 可以改成你想取的名字或路徑\n","np.save(save_path + PATH ,np.array(action_list)) "],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  \n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"asK7WfbkaLjt"},"source":["### 你要交到JudgeBoi的檔案94這個\n","儲存結果到本地端 (就是你的電腦裡拉 = = )\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"c-CqyhHzaWAL","executionInfo":{"elapsed":273,"status":"ok","timestamp":1624121524977,"user":{"displayName":"張君豪","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giewpu4H1RC4LywWkj1iyfrLc5i6hgwttwazWU6EQ=s64","userId":"03999016312843703738"},"user_tz":-480},"outputId":"067891b2-f2e2-492a-e809-da9e7d5848f9"},"source":["from google.colab import files\n","files.download(save_path + PATH)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_32ece476-a45d-4293-b717-7b288783be0a\", \"Action_List_test.npy\", 2681)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"seT4NUmWmAZ1"},"source":["# Server 測試\n","到時候下面會是我們Server上測試的環境，可以給大家看一下自己的表現如何"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":416},"id":"U69c-YTxaw6b","executionInfo":{"elapsed":1382,"status":"ok","timestamp":1624118627090,"user":{"displayName":"張君豪","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giewpu4H1RC4LywWkj1iyfrLc5i6hgwttwazWU6EQ=s64","userId":"03999016312843703738"},"user_tz":-480},"outputId":"7f95bd1b-25f8-4743-e313-635faa2ab87c"},"source":["action_list = np.load(save_path + PATH,allow_pickle=True) #到時候你上傳的檔案\n","seed = 543 #到時候測試的seed 請不要更改\n","fix(env, seed)\n","\n","agent.network.eval()  # 測試前先將 network 切換為 evaluation 模式\n","\n","test_total_reward = []\n","for actions in action_list:\n","  state = env.reset()\n","  img = plt.imshow(env.render(mode='rgb_array'))\n","\n","  total_reward = 0\n","\n","  done = False\n","  # while not done:\n","  done_count = 0\n","  for action in actions:\n","      # action, _ = agent1.sample(state)\n","      state, reward, done, _ = env.step(action)\n","      done_count += 1\n","      total_reward += reward\n","      if done:\n","        \n","        break\n","    #   img.set_data(env.render(mode='rgb_array'))\n","    #   display.display(plt.gcf())\n","    #   display.clear_output(wait=True)\n","  print(f\"Your reward is : %.2f\"%total_reward)\n","  test_total_reward.append(total_reward)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/__init__.py:422: UserWarning: torch.set_deterministic is deprecated and will be removed in a future release. Please use torch.use_deterministic_algorithms instead\n","  \"torch.set_deterministic is deprecated and will be removed in a future \"\n"],"name":"stderr"},{"output_type":"stream","text":["Your reward is : 262.21\n","Your reward is : 273.28\n","Your reward is : 223.88\n","Your reward is : 223.45\n","Your reward is : 273.97\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"TjFBWwQP1hVe"},"source":["# 你的成績"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GpJpZz3Wbm0X","executionInfo":{"elapsed":267,"status":"ok","timestamp":1624118631130,"user":{"displayName":"張君豪","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giewpu4H1RC4LywWkj1iyfrLc5i6hgwttwazWU6EQ=s64","userId":"03999016312843703738"},"user_tz":-480},"outputId":"671f7c4f-8616-47d6-8d3b-bb2e3331b876"},"source":["print(f\"Your final reward is : %.2f\"%np.mean(test_total_reward))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Your final reward is : 251.36\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wUBtYXG2eaqf"},"source":["## 參考資料\n","\n","以下是一些有用的參考資料。\n","建議同學們實做前，可以先參考第一則連結的上課影片。\n","在影片的最後有提到兩個有用的 Tips，這對於本次作業的實做非常有幫助。\n","\n","- [DRL Lecture 1: Policy Gradient (Review)](https://youtu.be/z95ZYgPgXOY)\n","- [ML Lecture 23-3: Reinforcement Learning (including Q-learning) start at 30:00](https://youtu.be/2-JNBzCq77c?t=1800)\n","- [Lecture 7: Policy Gradient, David Silver](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching_files/pg.pdf)\n","\n","* Sample code: https://colab.research.google.com/github/ga642381/ML2021-Spring/blob/main/HW12/HW12_ZH.ipynb\n"]}]}