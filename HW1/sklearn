{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"sklearn","provenance":[{"file_id":"https://github.com/ga642381/ML2021-Spring/blob/main/HW01/HW01.ipynb","timestamp":1615271751271}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"mz0_QVkxCrX3"},"source":["# **Homework 1: COVID-19 Cases Prediction (Regression)**"]},{"cell_type":"markdown","metadata":{"id":"ZeZnPAiwDRWG"},"source":["Author: Heng-Jui Chang\n","\n","Slides: https://github.com/ga642381/ML2021-Spring/blob/main/HW01/HW01.pdf  \n","Video: TBA\n","\n","Objectives:\n","* Solve a regression problem with deep neural networks (DNN).\n","* Understand basic DNN training tips.\n","* Get familiar with PyTorch.\n","\n","If any questions, please contact the TAs via TA hours, NTU COOL, or email.\n"]},{"cell_type":"markdown","metadata":{"id":"Jx3x1nDkG-Uy"},"source":["# **Download Data**\n","\n","\n","If the Google drive links are dead, you can download data from [kaggle](https://www.kaggle.com/c/ml2021spring-hw1/data), and upload data manually to the workspace."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tMj55YDKG6ch","executionInfo":{"status":"ok","timestamp":1616038880569,"user_tz":-480,"elapsed":2369,"user":{"displayName":"張君豪","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giewpu4H1RC4LywWkj1iyfrLc5i6hgwttwazWU6EQ=s64","userId":"03999016312843703738"}},"outputId":"abc1c89a-30c6-4188-f6de-e1438c6f1044"},"source":["tr_path = 'covid.train.csv'  # path to training data\n","tt_path = 'covid.test.csv'   # path to testing data\n","\n","!gdown --id '19CCyCgJrUxtvgZF53vnctJiOJ23T5mqF' --output covid.train.csv\n","!gdown --id '1CE240jLm2npU-tdz81-oVKEF3T2yfT1O' --output covid.test.csv"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=19CCyCgJrUxtvgZF53vnctJiOJ23T5mqF\n","To: /content/covid.train.csv\n","100% 2.00M/2.00M [00:00<00:00, 31.4MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1CE240jLm2npU-tdz81-oVKEF3T2yfT1O\n","To: /content/covid.test.csv\n","100% 651k/651k [00:00<00:00, 10.3MB/s]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wS_4-77xHk44"},"source":["# **Import Some Packages**"]},{"cell_type":"code","metadata":{"id":"k-onQd4JNA5H","executionInfo":{"status":"ok","timestamp":1616038884910,"user_tz":-480,"elapsed":6702,"user":{"displayName":"張君豪","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giewpu4H1RC4LywWkj1iyfrLc5i6hgwttwazWU6EQ=s64","userId":"03999016312843703738"}}},"source":["# PyTorch\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","\n","# sklearn\n","from sklearn import svm\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.ensemble import AdaBoostRegressor\n","\n","# For data preprocess\n","import numpy as np\n","import csv\n","import os\n","\n","# For plotting\n","import matplotlib.pyplot as plt\n","from matplotlib.pyplot import figure\n","\n","myseed = 1126  # set a random seed for reproducibility\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","np.random.seed(myseed)\n","torch.manual_seed(myseed)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(myseed)"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BtE3b6JEH7rw"},"source":["# **Some Utilities**\n","\n","You do not need to modify this part."]},{"cell_type":"code","metadata":{"id":"FWMT3uf1NGQp","executionInfo":{"status":"ok","timestamp":1616038884914,"user_tz":-480,"elapsed":5242,"user":{"displayName":"張君豪","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giewpu4H1RC4LywWkj1iyfrLc5i6hgwttwazWU6EQ=s64","userId":"03999016312843703738"}}},"source":["def get_device():\n","    ''' Get device (if GPU is available, use GPU) '''\n","    return 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","def plot_learning_curve(loss_record, title=''):\n","    ''' Plot learning curve of your DNN (train & dev loss) '''\n","    total_steps = len(loss_record['train'])\n","    x_1 = range(total_steps)\n","    x_2 = x_1[::len(loss_record['train']) // len(loss_record['dev'])]\n","    figure(figsize=(6, 4))\n","    plt.plot(x_1, loss_record['train'], c='tab:red', label='train')\n","    plt.plot(x_2, loss_record['dev'], c='tab:cyan', label='dev')\n","    plt.ylim(0.0, 5.)\n","    plt.xlabel('Training steps')\n","    plt.ylabel('MSE loss')\n","    plt.title('Learning curve of {}'.format(title))\n","    plt.legend()\n","    plt.show()\n","\n","\n","def plot_pred(dv_set, model, device, lim=35., preds=None, targets=None):\n","    ''' Plot prediction of your DNN '''\n","    if preds is None or targets is None:\n","        model.eval()\n","        preds, targets = [], []\n","        for x, y in dv_set:\n","            x, y = x.to(device), y.to(device)\n","            with torch.no_grad():\n","                pred = model(x)\n","                preds.append(pred.detach().cpu())\n","                targets.append(y.detach().cpu())\n","        preds = torch.cat(preds, dim=0).numpy()\n","        targets = torch.cat(targets, dim=0).numpy()\n","\n","    figure(figsize=(5, 5))\n","    plt.scatter(targets, preds, c='r', alpha=0.5)\n","    plt.plot([-0.2, lim], [-0.2, lim], c='b')\n","    plt.xlim(-0.2, lim)\n","    plt.ylim(-0.2, lim)\n","    plt.xlabel('ground truth value')\n","    plt.ylabel('predicted value')\n","    plt.title('Ground Truth v.s. Prediction')\n","    plt.show()"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"e6ML_ML8dDiw","executionInfo":{"status":"ok","timestamp":1616038884916,"user_tz":-480,"elapsed":1641,"user":{"displayName":"張君豪","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giewpu4H1RC4LywWkj1iyfrLc5i6hgwttwazWU6EQ=s64","userId":"03999016312843703738"}}},"source":["def RMSE(pred, y):\r\n","  mse = 0\r\n","  for i, j in zip(pred, y):\r\n","    mse += (i - j) ** 2\r\n","  mse /= len(y)\r\n","  \r\n","  return mse ** (1/2)"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"39U_XFX6KOoj"},"source":["# **Preprocess**\n","\n","We have three kinds of datasets:\n","* `train`: for training\n","* `dev`: for validation\n","* `test`: for testing (w/o target value)"]},{"cell_type":"markdown","metadata":{"id":"TQ-MdwpLL7Dt"},"source":["## **Dataset**\n","\n","The `COVID19Dataset` below does:\n","* read `.csv` files\n","* extract features\n","* split `covid.train.csv` into train/dev sets\n","* normalize features\n","\n","Finishing `TODO` below might make you pass medium baseline."]},{"cell_type":"code","metadata":{"id":"0zlpIp9ANJRU","executionInfo":{"status":"ok","timestamp":1616038888422,"user_tz":-480,"elapsed":691,"user":{"displayName":"張君豪","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giewpu4H1RC4LywWkj1iyfrLc5i6hgwttwazWU6EQ=s64","userId":"03999016312843703738"}}},"source":["class COVID19Dataset(Dataset):\n","    ''' Dataset for loading and preprocessing the COVID19 dataset '''\n","    def __init__(self,\n","                 path,\n","                 mode='train',\n","                 target_only=False):\n","        self.mode = mode\n","\n","        # Read data into numpy arrays\n","        with open(path, 'r') as fp:\n","            data = list(csv.reader(fp))\n","            data = np.array(data[1:])[:, 1:].astype(float)\n","        \n","        if not target_only:\n","            feats = list(range(93))\n","        else:\n","            # TODO: Using 40 states & 2 tested_positive features (indices = 57 & 75)\n","            # day_feats = [0, 4, 10, 11, 15, 17]\n","            # feats = [i + 40 for i in day_feats] + [i + 58 for i in day_feats] + [i + 76 for i in day_feats][:-1]\n","            feats = list(range(40, 93))\n","            pass\n","\n","        if mode == 'test':\n","            # Testing data\n","            # data: 893 x 93 (40 states + day 1 (18) + day 2 (18) + day 3 (17))\n","            data = data[:, feats]\n","            self.data = data\n","        else:\n","            # Training data (train/dev sets)\n","            # data: 2700 x 94 (40 states + day 1 (18) + day 2 (18) + day 3 (18))\n","            target = data[:, -1]\n","            data = data[:, feats]\n","\n","            # Splitting training data into train & dev sets\n","            if mode == 'train':\n","                indices = [i for i in range(len(data)) if i % 10 != 0]\n","            elif mode == 'dev':\n","                indices = [i for i in range(len(data)) if i % 10 == 0]\n","            \n","            # Convert data into PyTorch tensors\n","            self.data = data[indices]\n","            self.target = target[indices]\n","\n","        self.dim = len(self.data[1])\n","\n","        print('Finished reading the {} set of COVID19 Dataset ({} samples found, each dim = {})'\n","              .format(mode, len(self.data), self.dim))\n","\n","    def __getitem__(self, index):\n","        # Returns one sample at a time\n","        if self.mode in ['train', 'dev']:\n","            # For training\n","            return self.data[index], self.target[index]\n","        else:\n","            # For testing (no target)\n","            return self.data[index]\n","\n","    def __len__(self):\n","        # Returns the size of the dataset\n","        return len(self.data)"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AlhTlkE7MDo3"},"source":["## **DataLoader**\n","\n","A `DataLoader` loads data from a given `Dataset` into batches.\n"]},{"cell_type":"code","metadata":{"id":"hlhLk5t6MBX3","executionInfo":{"status":"ok","timestamp":1616038906757,"user_tz":-480,"elapsed":700,"user":{"displayName":"張君豪","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giewpu4H1RC4LywWkj1iyfrLc5i6hgwttwazWU6EQ=s64","userId":"03999016312843703738"}}},"source":["def prep_dataloader(path, mode, n_jobs=0, target_only=False):\n","    ''' Generates a dataset, then is put into a dataloader. '''\n","    dataset = COVID19Dataset(path, mode=mode, target_only=target_only)  # Construct dataset\n","    dataloader = DataLoader(\n","        dataset, batch_size=len(dataset.data),\n","        shuffle=(mode == 'train'), drop_last=False,\n","        num_workers=n_jobs, pin_memory=True)                            # Construct dataloader\n","    return dataloader"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SGuycwR0MeQB"},"source":["# **Deep Neural Network**\n","\n","`NeuralNet` is an `nn.Module` designed for regression.\n","The DNN consists of 2 fully-connected layers with ReLU activation.\n","This module also included a function `cal_loss` for calculating loss.\n"]},{"cell_type":"markdown","metadata":{"id":"DvFWVjZ5Nvga"},"source":["# **Train/Dev/Test**"]},{"cell_type":"markdown","metadata":{"id":"MAM8QecJOyqn"},"source":["## **Training**"]},{"cell_type":"code","metadata":{"id":"lOqcmYzMO7jB","executionInfo":{"status":"ok","timestamp":1616038910894,"user_tz":-480,"elapsed":663,"user":{"displayName":"張君豪","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giewpu4H1RC4LywWkj1iyfrLc5i6hgwttwazWU6EQ=s64","userId":"03999016312843703738"}}},"source":["def train(tr_set, model):\n","    ''' sklearn training '''\n","\n","    for x, y in tr_set:\n","      model.fit(x, y)\n","\n","    print('Finish training')"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WOPs6rW6_9ER"},"source":["## **Validating**"]},{"cell_type":"code","metadata":{"id":"wWMISTRHAE-b","executionInfo":{"status":"ok","timestamp":1616038913138,"user_tz":-480,"elapsed":777,"user":{"displayName":"張君豪","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giewpu4H1RC4LywWkj1iyfrLc5i6hgwttwazWU6EQ=s64","userId":"03999016312843703738"}}},"source":["def dev(dv_set, model):\r\n","    for x, y in dv_set:\r\n","      pred = model.predict(x)\r\n","      rmse_loss = RMSE(pred, y).detach().item()\r\n","\r\n","    print('dev rmse loss:', rmse_loss)"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g0pdrhQAO41L"},"source":["## **Testing**"]},{"cell_type":"code","metadata":{"id":"aSBMRFlYN5tB","executionInfo":{"status":"ok","timestamp":1616038915376,"user_tz":-480,"elapsed":664,"user":{"displayName":"張君豪","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giewpu4H1RC4LywWkj1iyfrLc5i6hgwttwazWU6EQ=s64","userId":"03999016312843703738"}}},"source":["def test(tt_set, model):\n","    preds = []\n","    for x in tt_set:                            # iterate through the dataloader\n","      pred = model.predict(x).tolist()                     # forward pass (compute output)\n","      preds += pred   # collect prediction\n","    preds = preds     # concatenate all predictions and convert to a numpy array\n","    return preds"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SvckkF5dvf0j"},"source":["# **Setup Hyper-parameters**\n","\n","`config` contains hyper-parameters for training and the path to save your model."]},{"cell_type":"code","metadata":{"id":"NPXpdumwPjE7","executionInfo":{"status":"ok","timestamp":1616039159539,"user_tz":-480,"elapsed":702,"user":{"displayName":"張君豪","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giewpu4H1RC4LywWkj1iyfrLc5i6hgwttwazWU6EQ=s64","userId":"03999016312843703738"}}},"source":["os.makedirs('models', exist_ok=True)  # The trained model will be saved to ./models/\n","target_only = True                   # TODO: Using 40 states & 2 tested_positive features"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6j1eOV3TOH-j"},"source":["# **Load data and model**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eNrYBMmePLKm","executionInfo":{"status":"ok","timestamp":1616039163405,"user_tz":-480,"elapsed":871,"user":{"displayName":"張君豪","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giewpu4H1RC4LywWkj1iyfrLc5i6hgwttwazWU6EQ=s64","userId":"03999016312843703738"}},"outputId":"c3a94949-a2b4-4314-b29a-1089db123207"},"source":["tr_set = prep_dataloader(tr_path, 'train', target_only=target_only)\n","dv_set = prep_dataloader(tr_path, 'dev', target_only=target_only)\n","tt_set = prep_dataloader(tt_path, 'test', target_only=target_only)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Finished reading the train set of COVID19 Dataset (2430 samples found, each dim = 53)\n","Finished reading the dev set of COVID19 Dataset (270 samples found, each dim = 53)\n","Finished reading the test set of COVID19 Dataset (893 samples found, each dim = 53)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FHylSirLP9oh","executionInfo":{"status":"ok","timestamp":1616039638671,"user_tz":-480,"elapsed":674,"user":{"displayName":"張君豪","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giewpu4H1RC4LywWkj1iyfrLc5i6hgwttwazWU6EQ=s64","userId":"03999016312843703738"}}},"source":["model = svm.SVR(kernel='linear', C=6)"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"pZlV_6ZLEVfL"},"source":["model = RandomForestRegressor(n_estimators=1000, n_jobs=-1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Lo0UcW9Ijlh"},"source":["model = AdaBoostRegressor(n_estimators=500, learning_rate=0.01)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sX2B_zgSOPTJ"},"source":["# **Start Training!**"]},{"cell_type":"code","metadata":{"id":"GrEbUxazQAAZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616039787194,"user_tz":-480,"elapsed":147218,"user":{"displayName":"張君豪","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giewpu4H1RC4LywWkj1iyfrLc5i6hgwttwazWU6EQ=s64","userId":"03999016312843703738"}},"outputId":"27f70b02-9e53-4b10-aaef-9c10b0bd16c9"},"source":["train(tr_set, model)"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Finish training\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"YTLtqCxWCsU0"},"source":["# **Validating**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-izRQcm6Cw5_","executionInfo":{"status":"ok","timestamp":1616039787199,"user_tz":-480,"elapsed":143918,"user":{"displayName":"張君豪","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giewpu4H1RC4LywWkj1iyfrLc5i6hgwttwazWU6EQ=s64","userId":"03999016312843703738"}},"outputId":"197d38a8-e52f-4707-dda7-8a32e276c606"},"source":["dev(dv_set, model)"],"execution_count":34,"outputs":[{"output_type":"stream","text":["dev rmse loss: 0.8926741786730633\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"aQikz3IPiyPf"},"source":["# **Testing**\n","The predictions of your model on testing set will be stored at `pred.csv`."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O8cTuQjQQOon","executionInfo":{"status":"ok","timestamp":1616039820741,"user_tz":-480,"elapsed":712,"user":{"displayName":"張君豪","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giewpu4H1RC4LywWkj1iyfrLc5i6hgwttwazWU6EQ=s64","userId":"03999016312843703738"}},"outputId":"9d509f9f-f983-465f-b161-2d95bdd9e00b"},"source":["def save_pred(preds, file):\n","    ''' Save predictions to specified file '''\n","    print('Saving results to {}'.format(file))\n","    with open(file, 'w') as fp:\n","        writer = csv.writer(fp)\n","        writer.writerow(['id', 'tested_positive'])\n","        for i, p in enumerate(preds):\n","            writer.writerow([i, p])\n","\n","preds = test(tt_set, model)  # predict COVID-19 cases with your model\n","save_pred(preds, 'pred.csv')         # save prediction file to pred.csv"],"execution_count":35,"outputs":[{"output_type":"stream","text":["Saving results to pred.csv\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nfrVxqJanGpE"},"source":["# **Hints**\n","\n","## **Simple Baseline**\n","* Run sample code\n","\n","## **Medium Baseline**\n","* Feature selection: 40 states + 2 `tested_positive` (`TODO` in dataset)\n","\n","## **Strong Baseline**\n","* Feature selection (what other features are useful?)\n","* DNN architecture (layers? dimension? activation function?)\n","* Training (mini-batch? optimizer? learning rate?)\n","* L2 regularization\n","* There are some mistakes in the sample code, can you find them?"]},{"cell_type":"markdown","metadata":{"id":"9tmCwXgpot3t"},"source":["# **Reference**\n","This code is completely written by Heng-Jui Chang @ NTUEE.  \n","Copying or reusing this code is required to specify the original author. \n","\n","E.g.  \n","Source: Heng-Jui Chang @ NTUEE (https://github.com/ga642381/ML2021-Spring/blob/main/HW01/HW01.ipynb)\n"]}]}